{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tflite_linear_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myidispg/TFLite_projects/blob/master/tflite_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkC-vDDHyi2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8bb45034-4f63-4457-edb2-178dcb7b7ef4"
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 26kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.7)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/9e/a48cd34dd7b672ffc227b566f7d16d63c62c58b542d54efa45848c395dd4/tensorboard-2.0.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 51.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (41.4.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/9b/ed0516cc1f7609fb0217e3057ff4f0f9f3e3ce79a369c6af4a6c5ca25664/google_auth-1.6.3-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.7)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.9.11)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
            "\u001b[31mERROR: tensorboard 2.0.1 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.6.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, google-auth, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed google-auth-1.6.3 tensorboard-2.0.1 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtjXktUIyuI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBD2grZhyzU6",
        "colab_type": "text"
      },
      "source": [
        "# Create a basic model of the form y=mx+c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKPi8RmEy2Ra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "57047bc8-9d2e-473b-d45e-68ba6f215f37"
      },
      "source": [
        "# Create a simple Keras model.\n",
        "x = [-1, 0, 1, 2, 3, 4]\n",
        "y = [-3, -1, 1, 3, 5, 7]\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(units=1, input_shape=[1])\n",
        "])\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "model.fit(x, y, epochs=200, verbose=1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6 samples\n",
            "Epoch 1/200\n",
            "6/6 [==============================] - 0s 75ms/sample - loss: 31.4938\n",
            "Epoch 2/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 25.0972\n",
            "Epoch 3/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 20.0581\n",
            "Epoch 4/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 16.0871\n",
            "Epoch 5/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 12.9567\n",
            "Epoch 6/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 10.4877\n",
            "Epoch 7/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 8.5391\n",
            "Epoch 8/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 7.0002\n",
            "Epoch 9/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 5.7836\n",
            "Epoch 10/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 4.8208\n",
            "Epoch 11/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 4.0577\n",
            "Epoch 12/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 3.4520\n",
            "Epoch 13/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 2.9700\n",
            "Epoch 14/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 2.5857\n",
            "Epoch 15/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 2.2781\n",
            "Epoch 16/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 2.0312\n",
            "Epoch 17/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 1.8320\n",
            "Epoch 18/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 1.6705\n",
            "Epoch 19/200\n",
            "6/6 [==============================] - 0s 969us/sample - loss: 1.5387\n",
            "Epoch 20/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 1.4304\n",
            "Epoch 21/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 1.3407\n",
            "Epoch 22/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 1.2657\n",
            "Epoch 23/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 1.2023\n",
            "Epoch 24/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 1.1483\n",
            "Epoch 25/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 1.1016\n",
            "Epoch 26/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 1.0607\n",
            "Epoch 27/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 1.0246\n",
            "Epoch 28/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.9923\n",
            "Epoch 29/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.9631\n",
            "Epoch 30/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.9364\n",
            "Epoch 31/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.9116\n",
            "Epoch 32/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.8886\n",
            "Epoch 33/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.8670\n",
            "Epoch 34/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.8465\n",
            "Epoch 35/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.8270\n",
            "Epoch 36/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.8083\n",
            "Epoch 37/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.7904\n",
            "Epoch 38/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.7732\n",
            "Epoch 39/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.7565\n",
            "Epoch 40/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.7403\n",
            "Epoch 41/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.7246\n",
            "Epoch 42/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.7093\n",
            "Epoch 43/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.6945\n",
            "Epoch 44/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.6800\n",
            "Epoch 45/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.6658\n",
            "Epoch 46/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.6520\n",
            "Epoch 47/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.6385\n",
            "Epoch 48/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.6253\n",
            "Epoch 49/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.6123\n",
            "Epoch 50/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.5997\n",
            "Epoch 51/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.5873\n",
            "Epoch 52/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.5752\n",
            "Epoch 53/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.5634\n",
            "Epoch 54/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.5518\n",
            "Epoch 55/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.5405\n",
            "Epoch 56/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.5293\n",
            "Epoch 57/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.5185\n",
            "Epoch 58/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.5078\n",
            "Epoch 59/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.4974\n",
            "Epoch 60/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.4871\n",
            "Epoch 61/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.4771\n",
            "Epoch 62/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.4673\n",
            "Epoch 63/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.4577\n",
            "Epoch 64/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.4483\n",
            "Epoch 65/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.4391\n",
            "Epoch 66/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.4301\n",
            "Epoch 67/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.4213\n",
            "Epoch 68/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.4126\n",
            "Epoch 69/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.4041\n",
            "Epoch 70/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.3958\n",
            "Epoch 71/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.3877\n",
            "Epoch 72/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.3797\n",
            "Epoch 73/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.3719\n",
            "Epoch 74/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.3643\n",
            "Epoch 75/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.3568\n",
            "Epoch 76/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.3495\n",
            "Epoch 77/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.3423\n",
            "Epoch 78/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.3353\n",
            "Epoch 79/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.3284\n",
            "Epoch 80/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.3216\n",
            "Epoch 81/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.3150\n",
            "Epoch 82/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.3086\n",
            "Epoch 83/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.3022\n",
            "Epoch 84/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.2960\n",
            "Epoch 85/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.2899\n",
            "Epoch 86/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.2840\n",
            "Epoch 87/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.2781\n",
            "Epoch 88/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.2724\n",
            "Epoch 89/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.2668\n",
            "Epoch 90/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.2614\n",
            "Epoch 91/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.2560\n",
            "Epoch 92/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.2507\n",
            "Epoch 93/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.2456\n",
            "Epoch 94/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.2405\n",
            "Epoch 95/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.2356\n",
            "Epoch 96/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.2308\n",
            "Epoch 97/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.2260\n",
            "Epoch 98/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.2214\n",
            "Epoch 99/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.2168\n",
            "Epoch 100/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.2124\n",
            "Epoch 101/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.2080\n",
            "Epoch 102/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.2037\n",
            "Epoch 103/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1995\n",
            "Epoch 104/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1955\n",
            "Epoch 105/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1914\n",
            "Epoch 106/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1875\n",
            "Epoch 107/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1837\n",
            "Epoch 108/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1799\n",
            "Epoch 109/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1762\n",
            "Epoch 110/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1726\n",
            "Epoch 111/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1690\n",
            "Epoch 112/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.1655\n",
            "Epoch 113/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1621\n",
            "Epoch 114/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1588\n",
            "Epoch 115/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1556\n",
            "Epoch 116/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1524\n",
            "Epoch 117/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.1492\n",
            "Epoch 118/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1462\n",
            "Epoch 119/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1432\n",
            "Epoch 120/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1402\n",
            "Epoch 121/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.1373\n",
            "Epoch 122/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1345\n",
            "Epoch 123/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1318\n",
            "Epoch 124/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1291\n",
            "Epoch 125/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.1264\n",
            "Epoch 126/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.1238\n",
            "Epoch 127/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.1213\n",
            "Epoch 128/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1188\n",
            "Epoch 129/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.1163\n",
            "Epoch 130/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1139\n",
            "Epoch 131/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1116\n",
            "Epoch 132/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.1093\n",
            "Epoch 133/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1071\n",
            "Epoch 134/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1049\n",
            "Epoch 135/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.1027\n",
            "Epoch 136/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.1006\n",
            "Epoch 137/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0985\n",
            "Epoch 138/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0965\n",
            "Epoch 139/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0945\n",
            "Epoch 140/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0926\n",
            "Epoch 141/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0907\n",
            "Epoch 142/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0888\n",
            "Epoch 143/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0870\n",
            "Epoch 144/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0852\n",
            "Epoch 145/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0835\n",
            "Epoch 146/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0817\n",
            "Epoch 147/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0801\n",
            "Epoch 148/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0784\n",
            "Epoch 149/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0768\n",
            "Epoch 150/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0752\n",
            "Epoch 151/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0737\n",
            "Epoch 152/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0722\n",
            "Epoch 153/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0707\n",
            "Epoch 154/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0692\n",
            "Epoch 155/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0678\n",
            "Epoch 156/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0664\n",
            "Epoch 157/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0651\n",
            "Epoch 158/200\n",
            "6/6 [==============================] - 0s 3ms/sample - loss: 0.0637\n",
            "Epoch 159/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0624\n",
            "Epoch 160/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0611\n",
            "Epoch 161/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0599\n",
            "Epoch 162/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0586\n",
            "Epoch 163/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0574\n",
            "Epoch 164/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0563\n",
            "Epoch 165/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0551\n",
            "Epoch 166/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0540\n",
            "Epoch 167/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0529\n",
            "Epoch 168/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0518\n",
            "Epoch 169/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0507\n",
            "Epoch 170/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0497\n",
            "Epoch 171/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0487\n",
            "Epoch 172/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0477\n",
            "Epoch 173/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0467\n",
            "Epoch 174/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0457\n",
            "Epoch 175/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0448\n",
            "Epoch 176/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0439\n",
            "Epoch 177/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0430\n",
            "Epoch 178/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0421\n",
            "Epoch 179/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0412\n",
            "Epoch 180/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0404\n",
            "Epoch 181/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0395\n",
            "Epoch 182/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0387\n",
            "Epoch 183/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0379\n",
            "Epoch 184/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0371\n",
            "Epoch 185/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0364\n",
            "Epoch 186/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0356\n",
            "Epoch 187/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0349\n",
            "Epoch 188/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0342\n",
            "Epoch 189/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0335\n",
            "Epoch 190/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0328\n",
            "Epoch 191/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0321\n",
            "Epoch 192/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0315\n",
            "Epoch 193/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0308\n",
            "Epoch 194/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0302\n",
            "Epoch 195/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0296\n",
            "Epoch 196/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0290\n",
            "Epoch 197/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0284\n",
            "Epoch 198/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0278\n",
            "Epoch 199/200\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 0.0272\n",
            "Epoch 200/200\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 0.0267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f32de2b4f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH-CcXhly5e5",
        "colab_type": "text"
      },
      "source": [
        "# Generate a saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G5fTuNty4CV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "17efe698-0a0a-470f-8f18-6a409ccf5f35"
      },
      "source": [
        "export_dir = 'saved_model/1'\n",
        "tf.saved_model.save(model, export_dir)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: saved_model/1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR-yxxb2y_Bn",
        "colab_type": "text"
      },
      "source": [
        "# Convert the SavedModel to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF5mfgg3zCGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "tflite_model = converter.convert()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxu700YvzDYU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4c6a951-28a6-4196-9cf1-f8933906e514"
      },
      "source": [
        "tflite_model_file = pathlib.Path('model.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "780"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGMs5lqHzHII",
        "colab_type": "text"
      },
      "source": [
        "# Initialize the TFLite Interpreter to try it out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30hSvCIpzL8m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0da69a43-d331-4bb1-afe4-ddc5832f2c36"
      },
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(f'Input: {input_details}')\n",
        "print(f'Output: {output_details}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: [{'name': 'dense_input', 'index': 3, 'shape': array([1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}]\n",
            "Output: [{'name': 'Identity', 'index': 0, 'shape': array([1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOHWzKs9zOiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test the TensorFlow Lite model on random input data.\n",
        "input_shape = input_details[0]['shape']\n",
        "inputs, outputs = [], []\n",
        "for _ in range(100):\n",
        "  input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
        "  interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "  interpreter.invoke()\n",
        "  tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "  # Test the TensorFlow model on random input data.\n",
        "  tf_results = model(tf.constant(input_data))\n",
        "  output_data = np.array(tf_results)\n",
        "  \n",
        "  inputs.append(input_data[0][0])\n",
        "  outputs.append(output_data[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh-oVDKRztSc",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGFHXK-dzsJj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8700861c-8aef-4106-d281-730085238f8a"
      },
      "source": [
        "plt.plot(inputs, outputs, 'r')\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcDUJiraz1z_",
        "colab_type": "text"
      },
      "source": [
        "## Download the TFLite model file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bp_1T_xz0Qn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "  files.download(tflite_model_file)\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxKJtnbWz0vd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}